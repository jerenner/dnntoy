{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from invisible_cities.io import pmap_io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from invisible_cities.reco.xy_algorithms import barycenter\n",
    "from invisible_cities.database import load_db\n",
    "from invisible_cities.reco.pmaps_functions import rebin_s2si\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find barycenter; first integrated energy over ALL peaks per sipm\n",
    "def get_barycenter(s2si, DataSiPM):\n",
    "    peaks=s2si.peak_collection()\n",
    "    dict_sum=Counter()\n",
    "    #sum all peaks inside one event\n",
    "    for peak in peaks:\n",
    "        dict_sum+=Counter(s2si.peak_and_sipm_total_energy_dict()[peak])\n",
    "\n",
    "    #map sipm number to coordinates    \n",
    "    coord=DataSiPM.loc[dict_sum.keys()][['X','Y']]\n",
    "    ene=[dict_sum[x] for x in dict_sum.keys()]\n",
    "    X_center,Y_center=barycenter(coord,ene)[0].X,barycenter(coord,ene)[0].Y\n",
    "    #find sipm that is the closest to the barycenter\n",
    "    \n",
    "    return 0.0,0.0\n",
    "    #return X_center, Y_center\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def event_energy(s2si):\n",
    "    peaks=s2si.peak_collection()\n",
    "    dict_sum=Counter()\n",
    "    #sum all peaks inside one event\n",
    "    for peak in peaks:\n",
    "        dict_sum+=Counter(s2si.peak_and_sipm_total_energy_dict()[peak])\n",
    "\n",
    "    #map sipm number to coordinates    \n",
    "    ene=[dict_sum[x] for x in dict_sum.keys()]\n",
    "    return ene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_xyt_array (s2si, DataSiPM,X_size, Y_size, t_size,t_step, xy_step=10, t_step_round=500):\n",
    "    X_center,Y_center=get_barycenter(s2si, DataSiPM)\n",
    "    \n",
    "    #take as center a sipm to the right up\n",
    "    X_center,Y_center=DataSiPM[(DataSiPM.X-X_center<xy_step)&(DataSiPM.X-X_center>0)\n",
    "                               &(DataSiPM.Y-Y_center<xy_step)&(DataSiPM.Y-Y_center>0)].iloc[0][['X','Y']]\n",
    "    peaks=s2si.peak_collection()\n",
    "    t_begin=round(s2si.peaks[peaks[0]].tmin_tmax.min//t_step_round)*t_step_round\n",
    "\n",
    "    x=np.linspace(X_center-X_size*10,X_center+X_size*10,endpoint=False,num=int(X_size*10/5))\n",
    "    y=np.linspace(Y_center-Y_size*10,Y_center+Y_size*10,endpoint=False,num=int(Y_size*10/5))\n",
    "    t=np.linspace(t_begin,t_begin+t_step*(t_size-1),int(t_size))\n",
    "    return x,y,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from invisible_cities.core.exceptions import *\n",
    "\n",
    "def E_per_sipm(s2si_rebin,DataSiPM,x,y,time_size,time_step):\n",
    "    E_xy=np.zeros(time_size)\n",
    "    try:\n",
    "        nsipm=np.asscalar(DataSiPM[(DataSiPM.X==x)&(DataSiPM.Y==y)].index)\n",
    "    except ValueError:\n",
    "        #print('no sipm')\n",
    "        return E_xy\n",
    "    peaks=s2si_rebin.peak_collection()\n",
    "\n",
    "    t_begin=round(s2si_rebin.peaks[0].t[0]//time_step)*time_step\n",
    "    for peak in peaks:\n",
    "        t_start=round(s2si_rebin.peaks[peak].t[0]//time_step)*time_step#s2si_rebin.peaks[peak].t[1]-time_step\n",
    "        indx_start=int((t_start-t_begin)//time_step)\n",
    "        indx_end=int(indx_start+len(s2si_rebin.peaks[peak].t))\n",
    "        try:\n",
    "            E_xy[indx_start:indx_end]=s2si_rebin.sipm_waveform(peak,nsipm).E\n",
    "        except ValueError:\n",
    "            #print('stopped at peak', peak)\n",
    "            E_xy[indx_start:time_size]=s2si_rebin.sipm_waveform(peak,nsipm).E[:time_size-indx_start]\n",
    "            break\n",
    "        except SipmNotFound as ex:\n",
    "            #print ('{}nsipm not in {}peak'.format(nsipm,peak))\n",
    "            return E_xy\n",
    "    return E_xy\n",
    "\n",
    "def E_tot(s2_rebin,time_size,time_step):\n",
    "    E=np.zeros(time_size)\n",
    "    peaks=s2_rebin.peak_collection()\n",
    "\n",
    "    t_begin=round(s2_rebin.peaks[0].t[0]//time_step)*time_step\n",
    "    for peak in peaks:\n",
    "        t_start=round(s2_rebin.peaks[peak].t[0]//time_step)*time_step\n",
    "        indx_start=int((t_start-t_begin)//time_step)\n",
    "        indx_end=int(indx_start+len(s2_rebin.peaks[peak].t))\n",
    "        try:\n",
    "            E[indx_start:indx_end]=s2_rebin.peak_waveform(peak).E\n",
    "        except ValueError:\n",
    "            #print('stopped at peak', peak)\n",
    "            E[indx_start:time_size]=s2_rebin.peak_waveform(peak).E[:time_size-indx_start]\n",
    "            break\n",
    "\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def josh_function(file_name,ev_nums,time_step,x_bins,y_bins,t_bins):\n",
    "    tensor_dict={}\n",
    "    energy_dict={}\n",
    "    run,events=pmap_io.read_run_and_event_from_pmaps_file(file_name)\n",
    "    run_num=np.asscalar(run.run_number.unique())\n",
    "    #find minimum and maximum event number inside the file and compare with ev_nums:\n",
    "    ev_min,ev_max=events.evt_number.min(),events.evt_number.max()\n",
    "    ev_nums=np.array(ev_nums)\n",
    "    ev_nums_file=ev_nums[(ev_nums>=ev_min) & (ev_nums<=ev_max)]\n",
    "    #if there are not events in ec_nums return empty dictionary\n",
    "    if ev_nums_file.size==0:\n",
    "        return tensor_dict,energy_dict\n",
    "    \n",
    "    s1_dict, s2_dict, s2si_dict=pmap_io.load_pmaps(file_name)\n",
    "    \n",
    "    DataPMT = load_db.DataPMT (run_num)\n",
    "    DataSiPM = load_db.DataSiPM(run_num)\n",
    "    X_min,X_max=DataSiPM.X.min(),DataSiPM.X.max()\n",
    "    Y_min,Y_max=DataSiPM.Y.min(),DataSiPM.Y.max()\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    for ev_indx,ev_num in enumerate(ev_nums_file):\n",
    "        try:\n",
    "            ev_s=np.asscalar(events[events['evt_number']==ev_num].evt_number.values)\n",
    "            print('event number {}'.format(ev_s))\n",
    "        except:\n",
    "            print('event number {} not found'.format(ev_num))\n",
    "            continue\n",
    "        \n",
    "        #rebin times\n",
    "        s2_rebin,s2si_rebin=rebin_s2si(s2_dict[ev_s], s2si_dict[ev_s], int(time_step/1000))\n",
    "    \n",
    "        x,y,t=make_xyt_array (s2si_rebin, DataSiPM,int(x_bins/2), int(y_bins/2), t_bins,time_step)\n",
    "\n",
    "        tensor=np.zeros((len(x),len(y),len(t)))\n",
    "        for ix,vx in enumerate(x):\n",
    "            for iy,vy in enumerate(y):\n",
    "                tensor[ix,iy,:]=E_per_sipm(s2si_rebin,DataSiPM,vx,vy,len(t),time_step)\n",
    "        ene=event_energy(s2si_rebin)\n",
    "        \n",
    "        epct = tensor.sum()/np.sum(ene)*100\n",
    "        print('energy_percent is {}'.format(epct))\n",
    "        if(epct > 95):\n",
    "\n",
    "            #normalize xy energies per time slice\n",
    "           # energy_per_time=(tensor.sum(axis=0)).sum(axis=0)\n",
    "           # energy_percentage=[1./x if x!=0. else 0. for x in energy_per_time]\n",
    "           # tensor=tensor*energy_percentage\n",
    "\n",
    "            #energies form pmts\n",
    "            ener= np.array(E_tot(s2si_rebin,len(t),time_step))\n",
    "            #normalize over all times\n",
    "           # tensor=tensor*ener/ener.sum()\n",
    "            #alltensors[ev_indx,:,:,:]=tensor\n",
    "            tensor_dict[ev_num]=tensor\n",
    "            energy_dict[ev_num]=ener\n",
    "            #print(ener)\n",
    "            #print(\"Energy array has {} elements\".format(len(ener)))\n",
    "        \n",
    "    return tensor_dict,energy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_data(time_step,x_bins,y_bins,t_bins):\n",
    "    def read_data(loc, rname, ev_nums, f_start=0, f_end=-1):\n",
    "        path_directory=loc.format(rname)\n",
    "        files = [join(path_directory, f) for f in listdir(path_directory) if isfile(join(path_directory, f))]\n",
    "        files=files[f_start:f_end]\n",
    "        tensor_dict={}\n",
    "        energy_dict={}\n",
    "        for fn in files:\n",
    "            dict_new,en_new = josh_function(fn,ev_nums,time_step,x_bins,y_bins,t_bins)\n",
    "            tensor_dict.update(dict_new)\n",
    "            energy_dict.update(en_new)\n",
    "        return tensor_dict,energy_dict\n",
    "    return read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NUMBER=4735\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data_location='/home/jrenner/analysis/{}/hdf5/pmaps'\n",
    "read_train=get_real_data(10000,48,48,48)\n",
    "evtfile = np.load(\"/data/fastmc/descape/classification/descape_evts_4735.npz\")\n",
    "evt_list = evtfile[\"A_evtnum\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jrenner/analysis/4735/hdf5/pmaps/pmaps_901_4735_icdev_20171006_th_th2000.h5\n"
     ]
    }
   ],
   "source": [
    "def find_file(loc, rname,ev_number): \n",
    "    path_directory=loc.format(rname)\n",
    "    files = [join(path_directory, f) for f in listdir(path_directory) if isfile(join(path_directory, f))]\n",
    "\n",
    "    for fn in files:\n",
    "        run,events=pmap_io.read_run_and_event_from_pmaps_file(fn)\n",
    "        run_num=np.asscalar(run.run_number.unique())\n",
    "        #find minimum and maximum event number inside the file and compare with ev_nums:\n",
    "        \n",
    "        if events[events.evt_number==ev_number].shape[0]!=0:\n",
    "            print (fn)\n",
    "            \n",
    "    \n",
    "find_file(data_location,RUN_NUMBER,100936) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event number 100936\n",
      "energy_percent is 98.91780332610591\n"
     ]
    }
   ],
   "source": [
    "d,ed=josh_function('/home/jrenner/analysis/4735/hdf5/pmaps/pmaps_901_4735_icdev_20171006_th_th2000.h5',[100936],10000,48,48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event number 238165\n",
      "energy_percent is 100.0\n",
      "event number 310094\n",
      "energy_percent is 100.0\n",
      "event number 310102\n",
      "energy_percent is 100.0\n",
      "event number 310120\n",
      "energy_percent is 100.0\n",
      "event number 115337\n",
      "energy_percent is 100.0\n",
      "event number 198076\n",
      "energy_percent is 100.0\n",
      "event number 64537\n",
      "energy_percent is 100.0\n",
      "event number 223465\n",
      "energy_percent is 100.0\n",
      "event number 317591\n",
      "energy_percent is 100.0\n",
      "event number 2847\n",
      "energy_percent is 100.0\n",
      "event number 113152\n",
      "energy_percent is 100.0\n",
      "event number 203711\n",
      "energy_percent is 100.0\n",
      "event number 204160\n"
     ]
    }
   ],
   "source": [
    "all_data,all_energies=read_train(data_location,RUN_NUMBER,evt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5maps = tb.open_file(\"data_4735_nonorm_nocenter_E.h5\", 'w')\n",
    "filters = tb.Filters(complib='blosc', complevel=9, shuffle=False)\n",
    "atom_m = tb.Atom.from_dtype(np.dtype('float32'))\n",
    "maparray = h5maps.create_earray(h5maps.root, 'maps', atom_m, (0, 48, 48, 48), filters=filters)\n",
    "atom_e = tb.Atom.from_dtype(np.dtype('int'))\n",
    "evtarray = h5maps.create_earray(h5maps.root, 'evtnum', atom_e, (0, 1), filters=filters)\n",
    "atom_en = tb.Atom.from_dtype(np.dtype('float32'))\n",
    "enarray = h5maps.create_earray(h5maps.root, 'energy', atom_en, (0, 48), filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in all_data.items():\n",
    "    evtnum = np.ones(1)*k\n",
    "    evtarray.append([evtnum])\n",
    "    maparray.append([v])\n",
    "for k,ee in all_energies.items():\n",
    "    enarray.append([ee])\n",
    "h5maps.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(all_data,open('pmaps_data.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches         import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xdim = 50\n",
    "ydim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NEW_SiPM_map_plot(xarr, normalize=True):\n",
    "    \"\"\"\n",
    "    Plots a SiPM map in the NEW Geometry\n",
    "    xarr is a NEW sipm map, yarr the pair of coordinates the map corresponds to\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        probs = (xarr - np.min(xarr))\n",
    "        probs /= np.max(probs)\n",
    "    else: \n",
    "        probs = xarr\n",
    "\n",
    "    # set up the figure\n",
    "    fig = plt.figure();\n",
    "    ax1 = fig.add_subplot(111);\n",
    "    fig.set_figheight(10.0)\n",
    "    fig.set_figwidth(10.0)\n",
    "    ax1.axis([0, 500, 0, 500]);\n",
    "\n",
    "    for i in range(xdim):\n",
    "        for j in range(ydim):\n",
    "            r = Ellipse(xy=(i * 10 + 5, j * 10 + 5), width=5., height=5.);\n",
    "            r.set_facecolor('0');\n",
    "            r.set_alpha(probs[i, j]);\n",
    "            ax1.add_artist(r);\n",
    "        \n",
    "    plt.xlabel(\"x (mm)\");\n",
    "    plt.ylabel(\"y (mm)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEW_SiPM_map_plot(all_data[1397][:,:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(all_data[1397][:,:,0])\n",
    "svals = []\n",
    "for key,value in all_data.items():\n",
    "    svals.append(np.sum(value[:,:,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh, bins, patches = plt.hist(svals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sum(hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
